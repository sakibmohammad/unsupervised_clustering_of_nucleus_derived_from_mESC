# this is just incase you want to see which value for k might be the best using elbow method 
sse = []
list_k = list(range(1, 10))

for k in list_k:
    km = KMeans(n_clusters=k, random_state=22)
    km.fit(x)
    
    sse.append(km.inertia_)

# Plot sse against k
plt.figure(figsize=(6, 6))
plt.plot(list_k, sse)
plt.xlabel(r'Number of clusters *k*')
plt.ylabel('Sum of squared distance');

# this is just incase you want to see which value for k might be the best using silhoutte method

from sklearn.metrics import silhouette_score

sil = []
kmax = 34

# dissimilarity would not be defined for a single cluster, thus, minimum number of clusters should be 2
for k in range(2, kmax+1):
  kmeans = KMeans(n_clusters = k).fit(x)
  labels = kmeans.labels_
  sil.append(silhouette_score(x, labels, metric = 'euclidean'))

# Plot sil against k
plt.figure(figsize=(6, 6))
plt.plot(list(range(2, 35)), sil)
plt.xlabel(r'Number of clusters *k*')
plt.ylabel('Sum of squared distance');
